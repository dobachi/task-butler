# Task Butler Configuration Example
#
# Location: ~/.task-butler/config.toml
#
# Configuration precedence (highest to lowest):
# 1. CLI options
# 2. Environment variables (TASK_BUTLER_FORMAT, TASK_BUTLER_DIR)
# 3. This config file
# 4. Default values

# ============================================
# Storage Settings
# ============================================
[storage]
# Storage format: "frontmatter" or "hybrid"
# - frontmatter: YAML frontmatter only (default)
# - hybrid: YAML frontmatter + Obsidian Tasks line
format = "frontmatter"

# Task storage directory (default: ~/.task-butler/tasks)
# dir = "/path/to/your/tasks"

# ============================================
# Obsidian Integration
# ============================================
[obsidian]
# Obsidian vault root (for linking support)
# vault_root = "/path/to/your/vault"

# ============================================
# Task Organization
# ============================================
# [organization]
# # Organization method: "flat" or "kanban"
# # - flat: All tasks in one directory (default)
# # - kanban: Status-based subdirectories
# method = "kanban"
#
# # Custom directory names for Kanban mode (optional)
# [organization.kanban]
# backlog = "Backlog"        # pending tasks
# in_progress = "InProgress" # tasks being worked on
# done = "Done"              # completed tasks
# cancelled = "Cancelled"    # cancelled tasks
#
# # After enabling kanban, run: task-butler organize
# # to move existing tasks to their status directories

# ============================================
# AI Settings
# ============================================
[ai]
# AI provider: "rule_based" (default), "llama", or "openai"
provider = "rule_based"

# Output language: "en" or "ja" (default)
language = "ja"

# LLM settings (when provider = "llama")
[ai.llama]
model_name = "tinyllama-1.1b"    # Model name (use 'tb ai models' to list)
# model_path = ""               # Or specify direct path to GGUF file
n_ctx = 2048                    # Context window size
n_gpu_layers = 0                # GPU layers (set to 99 for full GPU)

# Analysis weight settings
[ai.analysis]
weight_deadline = 0.30          # Deadline urgency weight
weight_dependencies = 0.25      # Dependency weight
weight_effort = 0.20            # Effort/complexity weight
weight_staleness = 0.15         # Task age weight
weight_priority = 0.10          # Manual priority weight

# Daily planning settings
[ai.planning]
default_hours = 8.0             # Default working hours per day
buffer_ratio = 0.1              # Buffer time ratio (10%)
morning_hours = 4.0             # Hours considered "morning"
start_time = "09:00"            # Work start time

# ============================================
# Custom Prompts (Optional)
# ============================================
# Customize AI prompts by language. Available placeholders:
#   {context} - Task details (title, priority, status, deadline, etc.)
#   {score}   - Rule-based priority score (0-100)
#   {title}   - Task title
#
# Use 'tb ai prompts' to see all available prompt keys
# Use 'tb ai prompts -p' to see all placeholders

# Japanese prompts
# [ai.prompts.ja]
# # Individual task analysis
# analyze_system = "あなたは優秀なタスク管理の専門家です。"
# analyze_user = "以下のタスクを分析してください:\n\n{context}\n\nスコア: {score}/100"
# # Holistic/portfolio analysis (tb analyze)
# portfolio_system = "あなたはタスク管理の専門家です。タスク一覧を俯瞰的に分析してください。"
# portfolio_user = "以下の{task_count}件のタスクを分析してください:\n\n{task_list}\n\n緊急性、グルーピング、注意点を簡潔に回答してください。"

# English prompts
# [ai.prompts.en]
# # Individual task analysis
# analyze_system = "You are an expert task management assistant."
# analyze_user = "Analyze this task:\n\n{context}\n\nScore: {score}/100"
# # Holistic/portfolio analysis (tb analyze)
# portfolio_system = "You are a task management expert. Analyze the task list holistically."
# portfolio_user = "Analyze these {task_count} tasks:\n\n{task_list}\n\nProvide urgency, grouping suggestions, and issues concisely."
